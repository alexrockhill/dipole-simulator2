
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_tutorial.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_tutorial.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_tutorial.py:


.. _main-tutorial:

============================
About Dipoles in MEG and EEG
============================

For an explanation of what is going on in the demo and background information
about magentoencephalography (MEG) and electroencephalography (EEG) in
general, let's walk through some code. To execute this code, you'll need
to have a working version of python with ``mne`` installed, see the
:ref:`quick-start` documentation for instructions. You'll need the development
version, so you'll need to do
``pip install git+https://github.com/mne-tools/mne-python.git`` You'll also
need to install the requirements such as with
``pip install -r requirements.txt``.

.. GENERATED FROM PYTHON SOURCE LINES 18-22

.. code-block:: default

    # Author: Alex Rockhill <aprockhill@mailbox.org>
    #
    # License: BSD-3-Clause








.. GENERATED FROM PYTHON SOURCE LINES 23-24

Let's start by importing the dependencies we'll need.

.. GENERATED FROM PYTHON SOURCE LINES 24-31

.. code-block:: default


    import os.path as op  # comes with python and helps naviagte to files
    import numpy as np  # a scientific computing package with arrays
    import matplotlib.pyplot as plt  # a plotting library
    import mne  # our main analysis software package
    from nilearn.plotting import plot_anat  # this package plots brains








.. GENERATED FROM PYTHON SOURCE LINES 32-38

Background
----------
MEG and EEG researchers record very small electromagentic potentials
generated by the brain from outside the head. When it comes from the
recording devices, it looks like this (there are a lot of channels
so only a subset are shown):

.. GENERATED FROM PYTHON SOURCE LINES 38-49

.. code-block:: default


    data_path = mne.datasets.sample.data_path()  # get the sample data path
    raw = mne.io.read_raw(  # navigate to some raw sample data
        op.join(data_path, 'MEG', 'sample', 'sample_audvis_raw.fif'))
    raw_plot = raw.copy()  # make a copy to modify for plotting
    raw_plot.pick_channels(raw.ch_names[::10])  # pick only every tenth channel
    raw_plot.plot(n_channels=len(raw_plot.ch_names),
                  duration=1,  # only a small, 1 second time window
                  start=50,  # start part way in
                  )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Opening raw data file /Users/alexrockhill/mne_data/MNE-sample-data/MEG/sample/sample_audvis_raw.fif...
        Read a total of 3 projection items:
            PCA-v1 (1 x 102)  idle
            PCA-v2 (1 x 102)  idle
            PCA-v3 (1 x 102)  idle
        Range : 25800 ... 192599 =     42.956 ...   320.670 secs
    Ready.
    Using qt as 2D backend.
    Opening raw-browser...
    /Users/alexrockhill/software/anaconda3/envs/mne/lib/python3.9/site-packages/mne_qt_browser/_pg_figure.py:2142: RuntimeWarning: Projection vector 'PCA-v1' has been reduced to 31.79% of its original magnitude by subselecting 10/102 of the original channels. If the ignored channels were bad during SSP computation, we recommend recomputing proj (via compute_proj_raw or related functions) with the bad channels properly marked, because computing SSP with bad channels present in the data but unmarked is dangerous (it can bias the PCA used by SSP). On the other hand, if you know that all channels were good during SSP computation, you can safely use info.normalize_proj() to suppress this warning during projection.
      BrowserBase.__init__(self, **kwargs)
    /Users/alexrockhill/software/anaconda3/envs/mne/lib/python3.9/site-packages/mne_qt_browser/_pg_figure.py:2142: RuntimeWarning: Projection vector 'PCA-v2' has been reduced to 33.07% of its original magnitude by subselecting 10/102 of the original channels. If the ignored channels were bad during SSP computation, we recommend recomputing proj (via compute_proj_raw or related functions) with the bad channels properly marked, because computing SSP with bad channels present in the data but unmarked is dangerous (it can bias the PCA used by SSP). On the other hand, if you know that all channels were good during SSP computation, you can safely use info.normalize_proj() to suppress this warning during projection.
      BrowserBase.__init__(self, **kwargs)
    /Users/alexrockhill/software/anaconda3/envs/mne/lib/python3.9/site-packages/mne_qt_browser/_pg_figure.py:2142: RuntimeWarning: Projection vector 'PCA-v3' has been reduced to 30.54% of its original magnitude by subselecting 10/102 of the original channels. If the ignored channels were bad during SSP computation, we recommend recomputing proj (via compute_proj_raw or related functions) with the bad channels properly marked, because computing SSP with bad channels present in the data but unmarked is dangerous (it can bias the PCA used by SSP). On the other hand, if you know that all channels were good during SSP computation, you can safely use info.normalize_proj() to suppress this warning during projection.
      BrowserBase.__init__(self, **kwargs)

    <mne_qt_browser._pg_figure.PyQtGraphBrowser object at 0x14f29b310>



.. GENERATED FROM PYTHON SOURCE LINES 50-55

The goal of MEG and EEG researchers is to try and understand how activity
in the brain changes as we respond to stimuli in our environment and
perform behaviors. To do that, researchers will often use magnetic resonance
(MR) to create an image of the research subject's brain. These images
look like this:

.. GENERATED FROM PYTHON SOURCE LINES 55-60

.. code-block:: default


    # first, get a T1-weighted MR scan file from the MNE example dataset
    T1_fname = op.join(data_path, 'subjects', 'sample', 'mri', 'T1.mgz')
    plot_anat(T1_fname)  # now we can plot it




.. image-sg:: /auto_examples/images/sphx_glr_plot_tutorial_001.png
   :alt: plot tutorial
   :srcset: /auto_examples/images/sphx_glr_plot_tutorial_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <nilearn.plotting.displays._slicers.OrthoSlicer object at 0x158ae0790>



.. GENERATED FROM PYTHON SOURCE LINES 61-72

The T1 MR image can be used to figure out where the surfaces of the
brain skull and scalp are as well as label the parts of the brain
in the image using Freesurfer. The command below does this (it takes
8 hours so I wouldn't recommend executing it now but it has already
been done for you in the mne sample data, see `here
<https://surfer.nmr.mgh.harvard.edu/fswiki/DownloadAndInstall>`_ for
how to install Freesurfer):

.. code-block:: bash

   recon-all -subjid sample -sd $DATA_PATH/subjects -i $T1_FNAME -all

.. GENERATED FROM PYTHON SOURCE LINES 74-89

Now let's put it all together and see the problem that MEG and EEG
researchers face in figuring out what's going on inside the brain from
electromagnetic potentials on the surface of the scalp. As you can see below,
there are a lot of MEG and EEG sensors and they cover a large portion of the
head but its not readily apparent how much of each brain area each sensor
records from and how to separate the summed activity from all the brain areas
that is recorded by each sensor into components for each brain area:

.. note::

    The sensor positions don't come aligned to the MR image since they are
    recorded by a different device so we need to a transformation matrix to
    transform them from the coordinate frame they are in to MR coordinates.
    This can be done with :func:`mne.gui.coregistration` to generate the
    ``trans`` file that is loaded below.

.. GENERATED FROM PYTHON SOURCE LINES 89-104

.. code-block:: default


    # the subjects_dir is where Freesurfer stored all the surface files
    subjects_dir = op.join(data_path, 'subjects')
    trans = mne.read_trans(op.join(data_path, 'MEG', 'sample',
                                   'sample_audvis_raw-trans.fif'))

    # the main plotter for mne, the brain object
    brain = mne.viz.Brain(subject_id='sample', hemi='both', surf='pial',
                          subjects_dir=subjects_dir)
    brain.add_skull(alpha=0.5)  # alpha sets transparency
    brain.add_head(alpha=0.5)
    brain.add_sensors(raw.info, trans)
    # set a nice view to show
    brain.show_view(azimuth=120, elevation=90, distance=500)




.. image-sg:: /auto_examples/images/sphx_glr_plot_tutorial_002.png
   :alt: plot tutorial
   :srcset: /auto_examples/images/sphx_glr_plot_tutorial_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Using pyvistaqt 3d backend.

    Using lh.seghead for head surface.
    Channel types:: grad: 203, mag: 102, eeg: 59
    Getting helmet for system 306m




.. GENERATED FROM PYTHON SOURCE LINES 105-115

Making a Source Space and Forward Model
---------------------------------------
First let's setup a space of vertices within the brain that we will consider
as the sources of signal. In a real brain, there are hundreds of billions
of cells but we don't have the resolution with only hundreds of sensors to
determine the activity of each cell, so, instead, we'll choose a regularly
sampled grid of sources that represent the summed activity of tens of
thousands of cells. In most analyses in publications, the source space has
around 8000 vertices, but, for this example, we'll use a smaller source
space for demonstration.

.. GENERATED FROM PYTHON SOURCE LINES 117-124

First, we would need to make a boundary element model (BEM) to account for
differences in conductivity of the brain, skull and scalp. This can be
done with :func:`mne.make_bem_model` but, in this case, we'll just load
a pre-computed model. We'll also load the solution to the BEM model for how
different conductivities of issues effect current dipoles as they pass
through each of the layers, but this can be computed with
:func:`mne.make_bem_solution`.

.. GENERATED FROM PYTHON SOURCE LINES 124-137

.. code-block:: default


    bem_fname = op.join(subjects_dir, 'sample', 'bem',
                        'sample-5120-5120-5120-bem.fif')

    # load a pre-computed solution the how the sources within the brain will
    # be affected by the different conductivities
    bem_sol = op.join(subjects_dir, 'sample', 'bem',
                      'sample-5120-5120-5120-bem-sol.fif')
    # plot it, it's saved out in a standard location,
    # so we don't have to pass the path
    mne.viz.plot_bem(subject='sample', subjects_dir=op.join(data_path, 'subjects'),
                     slices=np.linspace(45, 200, 12).round().astype(int))




.. image-sg:: /auto_examples/images/sphx_glr_plot_tutorial_003.png
   :alt: plot tutorial
   :srcset: /auto_examples/images/sphx_glr_plot_tutorial_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Using surface: /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/inner_skull.surf
    Using surface: /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/outer_skull.surf
    Using surface: /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/outer_skin.surf

    <MNEFigure size 780x731.5 with 12 Axes>



.. GENERATED FROM PYTHON SOURCE LINES 138-147

Making a Dipole
---------------
Now, we're ready to make a dipole and see how its current will be recorded
at the scalp with MEG and EEG.

.. note::

    You can use ``print(mne.Dipole.__doc__)`` to print the arguments that
    are required by ``mne.Dipole`` or any other class, method or function.

.. GENERATED FROM PYTHON SOURCE LINES 147-160

.. code-block:: default


    # make a dipole within the temporal lobe pointing superiorly,
    # fake a goodness-of-fit number
    dip_pos = [-0.0647572, 0.01315963, 0.07091921]
    dip = mne.Dipole(times=[0], pos=[dip_pos], amplitude=[3e-8],
                     ori=[[0, 0, 1]], gof=50)

    # plot it!
    brain = mne.viz.Brain(subject_id='sample', hemi='both', surf='pial',
                          subjects_dir=subjects_dir, alpha=0.25)
    brain.add_dipole(dip, trans, scales=10)
    brain.show_view(azimuth=150, elevation=60, distance=500)




.. image-sg:: /auto_examples/images/sphx_glr_plot_tutorial_004.png
   :alt: plot tutorial
   :srcset: /auto_examples/images/sphx_glr_plot_tutorial_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 161-167

Simulating Sensor Data
----------------------
We're ready to compute a forward operator using the BEM to make the so-called
leadfield matrix which multiplies activity at the dipole to give the
modelled the activity at the sensors. We can then use this to simulate evoked
data.

.. GENERATED FROM PYTHON SOURCE LINES 167-183

.. code-block:: default


    fwd, stc = mne.make_forward_dipole(
        dipole=dip, bem=bem_sol, info=raw.info, trans=trans)
    # we don't have a few things like the covarience matrix or a number of epochs
    # to average so we use these arguments for a reasonable solution
    evoked = mne.simulation.simulate_evoked(
        fwd, stc, raw.info, cov=None, nave=np.inf)

    # Now we can see what it would look like at the sensors
    fig, axes = plt.subplots(1, 3, figsize=(6, 4))  # make a figure with 3 subplots
    # use zip to iterate over axes and channel types at the same time
    for ax, ch_type in zip(axes, ('grad', 'mag', 'eeg')):
        # we're just looking at the relative pattern so we won't use a colorbar
        evoked.plot_topomap(times=[0], ch_type=ch_type, axes=ax, colorbar=False)
        ax.set_title(ch_type)




.. image-sg:: /auto_examples/images/sphx_glr_plot_tutorial_005.png
   :alt: grad, mag, eeg
   :srcset: /auto_examples/images/sphx_glr_plot_tutorial_005.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Positions (in meters) and orientations
    1 sources
    Source space          : <SourceSpaces: [<discrete, n_used=1>] head coords, ~2 kB>
    MRI -> head transform : instance of Transform
    Measurement data      : instance of Info
    Conductor model   : /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem-sol.fif
    Accurate field computations
    Do computations in head coordinates
    Free source orientations

    Read 1 source spaces a total of 1 active source locations

    Coordinate transformation: MRI (surface RAS) -> head
         0.999310  0.009985 -0.035787      -3.17 mm
         0.012759  0.812405  0.582954       6.86 mm
         0.034894 -0.583008  0.811716      28.88 mm
         0.000000  0.000000  0.000000       1.00

    Read 306 MEG channels from info
    105 coil definitions read
    Coordinate transformation: MEG device -> head
         0.991420 -0.039936 -0.124467      -6.13 mm
         0.060661  0.984012  0.167456       0.06 mm
         0.115790 -0.173570  0.977991      64.74 mm
         0.000000  0.000000  0.000000       1.00
    MEG coil definitions created in head coordinates.
    Read  60 EEG channels from info
    Head coordinate coil definitions created.
    Source spaces are now in head coordinates.

    Setting up the BEM model using /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem-sol.fif...

    Loading surfaces...

    Loading the solution matrix...

    Three-layer model surfaces loaded.
    Loaded linear_collocation BEM solution from /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem-sol.fif
    Employing the head->MRI coordinate transform with the BEM model.
    BEM model sample-5120-5120-5120-bem-sol.fif is now set up

    Source spaces are in head coordinates.
    Checking that the sources are inside the surface (will take a few...)
        Skipping interior check for 0 sources that fit inside a sphere of radius   43.6 mm
        Skipping solid angle check for 0 points using Qhull

        Skipping interior check for 0 sources that fit inside a sphere of radius   79.1 mm
        Skipping solid angle check for 306 points using Qhull
    Setting up compensation data...
        No compensation set. Nothing more to do.

    Composing the field computation matrix...
    Setting up for EEG...
    Computing MEG at 1 source location (free orientations)...
    Computing EEG at 1 source location (free orientations)...

    Finished.
        Changing to fixed-orientation forward solution with surface-based source orientations...
        [done]
    /Users/alexrockhill/projects/dipole-simulator2/examples/plot_tutorial.py:172: RuntimeWarning: Source estimate only contains currents with positive values. Use pick_ori="normal" when computing the inverse to compute currents not current magnitudes.
      evoked = mne.simulation.simulate_evoked(
    Projecting source estimate to sensor space...
    [done]




.. GENERATED FROM PYTHON SOURCE LINES 184-195

Wrapping Up
-----------
We covered some good intuition but there's lots more to learn! The main thing
is that MEG and EEG researchers generally don't have the information about
what's going on inside the brain, that's what they are trying to predict. To
reverse this process, you need to invert the forward solution (tutorial:
:ref:`tut-viz-stcs`). There is tons more to explore in the MNE `tutorials
<https://mne.tools/dev/auto_tutorials/index.html>`_ and `examples
<https://mne.tools/dev/auto_examples/index.html>`_ pages. Let's leave off by
setting up a source space of many different dipoles and seeing their
different activities manifest on the scalp as measured by the sensors.

.. GENERATED FROM PYTHON SOURCE LINES 195-211

.. code-block:: default


    src = mne.setup_volume_source_space(
        subject='sample', pos=20,  # in mm
        bem=bem_fname, subjects_dir=subjects_dir)

    # make the leadfield matrix
    fwd = mne.make_forward_solution(
        raw.info, trans=trans, src=src, bem=bem_sol)

    # plot our setup
    brain = mne.viz.Brain(subject_id='sample', hemi='both', surf='pial',
                          subjects_dir=subjects_dir, alpha=0.25)
    brain.add_volume_labels(alpha=0.25, colors='gray')
    brain.add_forward(fwd, trans, scale=3)
    brain.show_view(azimuth=30, elevation=90, distance=500)




.. image-sg:: /auto_examples/images/sphx_glr_plot_tutorial_006.png
   :alt: plot tutorial
   :srcset: /auto_examples/images/sphx_glr_plot_tutorial_006.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    BEM              : /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem.fif
    grid                  : 20.0 mm
    mindist               : 5.0 mm
    MRI volume            : /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/mri/T1.mgz

    Reading /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/mri/T1.mgz...

    Loaded inner skull from /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem.fif (2562 nodes)
    Surface CM = (   0.7  -10.0   44.3) mm
    Surface fits inside a sphere with radius   91.8 mm
    Surface extent:
        x =  -66.7 ...   68.8 mm
        y =  -88.0 ...   79.0 mm
        z =  -44.5 ...  105.8 mm
    Grid extent:
        x =  -80.0 ...   80.0 mm
        y = -100.0 ...   80.0 mm
        z =  -60.0 ...  120.0 mm
    900 sources before omitting any.
    400 sources after omitting infeasible sources not within 0.0 - 91.8 mm.
    Source spaces are in MRI coordinates.
    Checking that the sources are inside the surface and at least    5.0 mm away (will take a few...)
        Skipping interior check for 46 sources that fit inside a sphere of radius   43.6 mm
        Skipping solid angle check for 186 points using Qhull
        195 source space points omitted because they are outside the inner skull surface.
        45 source space points omitted because of the    5.0-mm distance limit.
    160 sources remaining after excluding the sources outside the surface and less than    5.0 mm inside.
    Adjusting the neighborhood info.
    Source space : MRI voxel -> MRI (surface RAS)
         0.020000  0.000000  0.000000     -80.00 mm
         0.000000  0.020000  0.000000    -100.00 mm
         0.000000  0.000000  0.020000     -60.00 mm
         0.000000  0.000000  0.000000       1.00
    MRI volume : MRI voxel -> MRI (surface RAS)
        -0.001000  0.000000  0.000000     128.00 mm
         0.000000  0.000000  0.001000    -128.00 mm
         0.000000 -0.001000  0.000000     128.00 mm
         0.000000  0.000000  0.000000       1.00
    MRI volume : MRI (surface RAS) -> RAS (non-zero origin)
         1.000000 -0.000000 -0.000000      -5.27 mm
        -0.000000  1.000000 -0.000000       9.04 mm
        -0.000000  0.000000  1.000000     -27.29 mm
         0.000000  0.000000  0.000000       1.00
    Setting up volume interpolation ...
        17547230/16777216 nonzero values for the whole brain
    [done]
    Source space          : <SourceSpaces: [<volume, shape=(9, 10, 10), n_used=160>] MRI (surface RAS) coords, subject 'sample', ~64.2 MB>
    MRI -> head transform : instance of Transform
    Measurement data      : instance of Info
    Conductor model   : /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem-sol.fif
    Accurate field computations
    Do computations in head coordinates
    Free source orientations

    Read 1 source spaces a total of 160 active source locations

    Coordinate transformation: MRI (surface RAS) -> head
         0.999310  0.009985 -0.035787      -3.17 mm
         0.012759  0.812405  0.582954       6.86 mm
         0.034894 -0.583008  0.811716      28.88 mm
         0.000000  0.000000  0.000000       1.00

    Read 306 MEG channels from info
    105 coil definitions read
    Coordinate transformation: MEG device -> head
         0.991420 -0.039936 -0.124467      -6.13 mm
         0.060661  0.984012  0.167456       0.06 mm
         0.115790 -0.173570  0.977991      64.74 mm
         0.000000  0.000000  0.000000       1.00
    MEG coil definitions created in head coordinates.
    Read  60 EEG channels from info
    Head coordinate coil definitions created.
    Source spaces are now in head coordinates.

    Setting up the BEM model using /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem-sol.fif...

    Loading surfaces...

    Loading the solution matrix...

    Three-layer model surfaces loaded.
    Loaded linear_collocation BEM solution from /Users/alexrockhill/mne_data/MNE-sample-data/subjects/sample/bem/sample-5120-5120-5120-bem-sol.fif
    Employing the head->MRI coordinate transform with the BEM model.
    BEM model sample-5120-5120-5120-bem-sol.fif is now set up

    Source spaces are in head coordinates.
    Checking that the sources are inside the surface (will take a few...)
        Skipping interior check for 46 sources that fit inside a sphere of radius   43.6 mm
        Skipping solid angle check for 0 points using Qhull

        Skipping interior check for 0 sources that fit inside a sphere of radius   79.1 mm
        Skipping solid angle check for 306 points using Qhull
    Setting up compensation data...
        No compensation set. Nothing more to do.

    Composing the field computation matrix...
    Setting up for EEG...
    Computing MEG at 160 source locations (free orientations)...
    Computing EEG at 160 source locations (free orientations)...

    Finished.




.. GENERATED FROM PYTHON SOURCE LINES 212-213

Plot the same solution using a source space of dipoles

.. GENERATED FROM PYTHON SOURCE LINES 213-237

.. code-block:: default


    # take the source space from the forward model because some of the
    # vertices are excluded from the vertices in src
    n_dipoles = fwd['source_rr'].shape[0]  # rr is the vertex positions
    # find the closest dipole to the one we used before (it was in this
    # source space) using the euclidean distance (np.linalg.norm)
    idx = np.argmin(np.linalg.norm(fwd['source_rr'] - dip_pos, axis=1))
    # make an empty matrix of zeros
    data = np.zeros((n_dipoles, 3, 1))
    data[idx, 2, 0] = 3e-8  # make the same dipole as before
    # this is the format that vertiex numbers are stored in
    vertices = [fwd['src'][0]['vertno']]
    stc = mne.VolVectorSourceEstimate(data, vertices=vertices,
                                      subject='sample', tmin=0, tstep=1)

    evoked = mne.simulation.simulate_evoked(
        fwd, stc, raw.info, cov=None, nave=np.inf)

    # confirm our replication
    fig, axes = plt.subplots(1, 3, figsize=(6, 4))  # make a figure with 3 subplots
    for ax, ch_type in zip(axes, ('grad', 'mag', 'eeg')):
        evoked.plot_topomap(times=[0], ch_type=ch_type, axes=ax, colorbar=False)
        ax.set_title(ch_type)




.. image-sg:: /auto_examples/images/sphx_glr_plot_tutorial_007.png
   :alt: grad, mag, eeg
   :srcset: /auto_examples/images/sphx_glr_plot_tutorial_007.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

        Cartesian source orientations...
        [done]
    Projecting source estimate to sensor space...
    [done]




.. GENERATED FROM PYTHON SOURCE LINES 238-239

Now, go crazy and simulate a bunch of random dipoles

.. GENERATED FROM PYTHON SOURCE LINES 239-252

.. code-block:: default


    np.random.seed(88)  # always seed random number generation for reproducibility
    stc.data = np.random.random(stc.data.shape) * 3e-8 - 1.5e-8
    evoked = mne.simulation.simulate_evoked(
        fwd, stc, raw.info, cov=None, nave=np.inf)

    # now that's a complicated faked brain pattern, fortunately brain activity
    # is much more correlated (neighboring areas have similar activity) which
    # makes results a bit easier to interpret
    fig, axes = plt.subplots(1, 3, figsize=(6, 4))  # make a figure with 3 subplots
    for ax, ch_type in zip(axes, ('grad', 'mag', 'eeg')):
        evoked.plot_topomap(times=[0], ch_type=ch_type, axes=ax, colorbar=False)
        ax.set_title(ch_type)



.. image-sg:: /auto_examples/images/sphx_glr_plot_tutorial_008.png
   :alt: grad, mag, eeg
   :srcset: /auto_examples/images/sphx_glr_plot_tutorial_008.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

        Cartesian source orientations...
        [done]
    Projecting source estimate to sensor space...
    [done]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  39.903 seconds)


.. _sphx_glr_download_auto_examples_plot_tutorial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_tutorial.py <plot_tutorial.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_tutorial.ipynb <plot_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
